{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hbol",
   "metadata": {
    "marimo": {
     "name": "setup_marimo"
    }
   },
   "outputs": [],
   "source": [
    "import marimo as mo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MJUe",
   "metadata": {
    "marimo": {
     "name": "intro_md"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vblA",
   "metadata": {
    "marimo": {
     "name": "section1_md"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bkHC",
   "metadata": {
    "marimo": {
     "name": "std_imports"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import tempfile\n",
    "import atexit\n",
    "import importlib.util\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import logging\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "PathRef = Path\n",
    "# Return only what is used in other cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lEQa",
   "metadata": {
    "marimo": {
     "name": "verify_packages"
    }
   },
   "outputs": [],
   "source": [
    "# Explicitly check for required dependencies before proceeding\n",
    "pkg_map = {\n",
    "    \"pyyaml\": \"yaml\",\n",
    "}\n",
    "\n",
    "# CRITICAL LOGIC CHECK: Ensure 'pyacemaker' is installed OR available in src\n",
    "# We check it first to fail fast.\n",
    "has_pyacemaker_pkg = False\n",
    "pyacemaker_spec = None # Initialize to avoid NameError\n",
    "try:\n",
    "    pyacemaker_spec = importlib.util.find_spec(\"pyacemaker\")\n",
    "    if pyacemaker_spec is not None:\n",
    "        has_pyacemaker_pkg = True\n",
    "except (ImportError, AttributeError):\n",
    "    pass\n",
    "\n",
    "if not has_pyacemaker_pkg:\n",
    "    # Check if we are in repo root and can add src\n",
    "    # We look for src/pyacemaker relative to CWD\n",
    "    src_exists = Path(\"src/pyacemaker\").exists() or Path(\"../src/pyacemaker\").exists()\n",
    "\n",
    "    if src_exists:\n",
    "        print(\"Found source directory. Will attempt to load from there.\")\n",
    "    else:\n",
    "        mo.md(\n",
    "            \"\"\"\n",
    "            ::: error\n",
    "            **CRITICAL ERROR: `pyacemaker` is not installed.**\n",
    "\n",
    "            This tutorial requires the `pyacemaker` package to be installed in the environment or the source code to be present in `src/`.\n",
    "\n",
    "            **Installation Instructions:**\n",
    "            1.  Open your terminal.\n",
    "            2.  Navigate to the project root.\n",
    "            3.  Run:\n",
    "                ```bash\n",
    "                uv sync\n",
    "                # OR\n",
    "                pip install -e .[dev]\n",
    "                ```\n",
    "            4.  Restart this notebook.\n",
    "            :::\n",
    "            \"\"\"\n",
    "        )\n",
    "        # We don't raise error here if src exists, we let path_setup handle it\n",
    "        pass\n",
    "\n",
    "required_packages = [\"ase\", \"numpy\", \"matplotlib\", \"pyyaml\", \"pydantic\"]\n",
    "missing = []\n",
    "\n",
    "for pkg in required_packages:\n",
    "    module_name = pkg_map.get(pkg, pkg)\n",
    "    if importlib.util.find_spec(module_name) is None:\n",
    "        missing.append(pkg)\n",
    "\n",
    "if missing:\n",
    "    error_msg = f\"Missing Dependencies: {', '.join(missing)}\"\n",
    "    mo.md(\n",
    "        f\"\"\"\n",
    "        ::: error\n",
    "        **CRITICAL ERROR: {error_msg}**\n",
    "\n",
    "        The tutorial cannot proceed without these packages.\n",
    "\n",
    "        **Action Required:**\n",
    "        ```bash\n",
    "        uv sync\n",
    "        # OR\n",
    "        pip install -e .[dev]\n",
    "        ```\n",
    "        :::\n",
    "        \"\"\"\n",
    "    )\n",
    "    # Halt execution by raising an error if run as a script/notebook\n",
    "    raise ImportError(error_msg)\n",
    "else:\n",
    "    print(\"All required packages found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PKri",
   "metadata": {
    "marimo": {
     "name": "check_api_keys"
    }
   },
   "outputs": [],
   "source": [
    "# CONSTITUTION CHECK: Graceful handling of API Keys\n",
    "mp_api_key = None\n",
    "has_api_key = False\n",
    "api_key_status = None\n",
    "\n",
    "if os is not None:\n",
    "    mp_api_key = os.environ.get(\"MP_API_KEY\")\n",
    "\n",
    "    if mp_api_key:\n",
    "        has_api_key = True\n",
    "        api_key_status = mo.md(\n",
    "            \"::: success\\n✅ **MP_API_KEY found.** Advanced exploration strategies enabled.\\n:::\"\n",
    "        )\n",
    "        print(\"✅ MP_API_KEY found.\")\n",
    "    else:\n",
    "        api_key_status = mo.md(\n",
    "            \"\"\"\n",
    "            ::: warning\n",
    "            **Missing API Key: `MP_API_KEY`**\n",
    "\n",
    "            The **Materials Project API Key** was not found in the environment variables.\n",
    "\n",
    "            *   **Impact**: Strategies relying on M3GNet/Materials Project (e.g., \"smart\" Cold Start) will be disabled or mocked.\n",
    "            *   **Fallback**: We will default to the **'Random'** exploration strategy, which generates random structures. This ensures the tutorial runs without errors.\n",
    "            *   **How to Fix**:\n",
    "                1.  **Get a Key**: Sign up at [Materials Project](https://next-gen.materialsproject.org/api) to get your API key.\n",
    "                2.  **Set Environment Variable**:\n",
    "                    *   **Linux/Mac**: Run `export MP_API_KEY='your_key_here'` in your terminal before starting Marimo.\n",
    "                    *   **Windows**: Set the environment variable in System Properties or PowerShell (`$env:MP_API_KEY='your_key_here'`).\n",
    "            :::\n",
    "            \"\"\"\n",
    "        )\n",
    "        print(\"⚠️ No MP_API_KEY. Defaulting to 'Random' strategy.\")\n",
    "else:\n",
    "    print(\"⚠️ Warning: `os` module not available. Cannot check environment variables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Xref",
   "metadata": {
    "marimo": {
     "name": "sci_imports"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "# NOTE: In Marimo, this cell runs once unless variables change.\n",
    "# To be safe, we re-seed in stochastic cells if necessary,\n",
    "# but global seeding here covers most cases.\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SFPL",
   "metadata": {
    "marimo": {
     "name": "reproducibility_md"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BYtC",
   "metadata": {
    "marimo": {
     "name": "path_setup"
    }
   },
   "outputs": [],
   "source": [
    "current_wd = None\n",
    "possible_src_paths = []\n",
    "src_path = None\n",
    "\n",
    "if PathRef is not None and sys is not None:\n",
    "    # Locate src directory\n",
    "    # Rename to avoid global scope conflict with setup_config\n",
    "    current_wd = PathRef.cwd()\n",
    "    possible_src_paths = [\n",
    "        current_wd / \"src\",\n",
    "        current_wd.parent / \"src\",\n",
    "    ]\n",
    "\n",
    "    for p in possible_src_paths:\n",
    "        if (p / \"pyacemaker\" / \"__init__.py\").exists():\n",
    "            src_path = p\n",
    "            break\n",
    "\n",
    "    if src_path:\n",
    "        if str(src_path) not in sys.path:\n",
    "            sys.path.append(str(src_path))\n",
    "            print(f\"Added {src_path} to sys.path\")\n",
    "    else:\n",
    "        # Only warn if verify_packages didn't find it installed either\n",
    "        pass\n",
    "else:\n",
    "    mo.md(\"::: error\\n**Fatal Error**: Standard libraries `pathlib` or `sys` are not available.\\n:::\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RGSE",
   "metadata": {
    "marimo": {
     "name": "package_import"
    }
   },
   "outputs": [],
   "source": [
    "# Dummy usage to enforce dependency\n",
    "_ = src_path\n",
    "\n",
    "# Initialize variables to avoid UnboundLocalError\n",
    "CONSTANTS = None\n",
    "Orchestrator = None\n",
    "PYACEMAKERConfig = None\n",
    "Potential = None\n",
    "PotentialHelper = None\n",
    "StructureMetadata = None\n",
    "StructureStatus = None\n",
    "StructureGenerator = None\n",
    "BaseModule = None\n",
    "Metrics = None\n",
    "ModuleResult = None\n",
    "metadata_to_atoms = None\n",
    "pyacemaker = None\n",
    "HAS_PYACEMAKER = False\n",
    "\n",
    "error_md = None\n",
    "\n",
    "try:\n",
    "    # 1. Base Import\n",
    "    import pyacemaker\n",
    "\n",
    "    # 2. Core Config\n",
    "    from pyacemaker.core.config import PYACEMAKERConfig, CONSTANTS\n",
    "\n",
    "    # 3. Orchestrator\n",
    "    from pyacemaker.orchestrator import Orchestrator\n",
    "\n",
    "    # 4. Domain Models\n",
    "    from pyacemaker.domain_models.models import (\n",
    "        Potential,\n",
    "        StructureMetadata,\n",
    "        StructureStatus,\n",
    "    )\n",
    "\n",
    "    # 5. Dynamics (PotentialHelper is in modules.dynamics_engine)\n",
    "    from pyacemaker.modules.dynamics_engine import PotentialHelper\n",
    "\n",
    "    # 6. Utils\n",
    "    from pyacemaker.core.utils import metadata_to_atoms\n",
    "\n",
    "    # 7. Core Interfaces & Base\n",
    "    from pyacemaker.core.interfaces import StructureGenerator\n",
    "    from pyacemaker.core.base import BaseModule, Metrics, ModuleResult\n",
    "\n",
    "    HAS_PYACEMAKER = True\n",
    "    print(f\"Successfully imported pyacemaker components from {pyacemaker.__file__}\")\n",
    "\n",
    "except ImportError as e:\n",
    "    HAS_PYACEMAKER = False\n",
    "    error_md = mo.md(\n",
    "        f\"\"\"\n",
    "        ::: error\n",
    "        **Import Error**: {e}\n",
    "\n",
    "        Failed to import a specific module from `pyacemaker`. This usually indicates a broken installation or version mismatch.\n",
    "        :::\n",
    "        \"\"\"\n",
    "    )\n",
    "except Exception as e:\n",
    "    HAS_PYACEMAKER = False\n",
    "    error_md = mo.md(f\"::: error\\n**Unexpected Error:** {e}\\n:::\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Kclp",
   "metadata": {
    "marimo": {
     "name": "check_dependencies"
    }
   },
   "outputs": [],
   "source": [
    "# Dependency Check\n",
    "required_binaries = [\"pw.x\", \"lmp\", \"pace_train\"]\n",
    "found_binaries = {}\n",
    "missing_binaries = []\n",
    "\n",
    "IS_CI = True  # Default safe\n",
    "mode_name = \"Mock Mode (CI)\"\n",
    "raw_ci = \"true\"\n",
    "valid_true = [\"true\", \"1\", \"yes\", \"on\"]\n",
    "valid_false = [\"false\", \"0\", \"no\", \"off\"]\n",
    "status_md = \"\"\n",
    "fallback_msg = None\n",
    "\n",
    "if os is not None and shutil is not None:\n",
    "    for binary in required_binaries:\n",
    "        bin_path = shutil.which(binary)\n",
    "        if bin_path:\n",
    "            found_binaries[binary] = bin_path\n",
    "        else:\n",
    "            missing_binaries.append(binary)\n",
    "\n",
    "    # Detect Mode\n",
    "    # Default to CI/Mock mode if not explicitly set to false/0/no/off\n",
    "    raw_ci = os.environ.get(\"CI\", \"true\").strip().lower()\n",
    "\n",
    "    # Initial decision based on Env Var\n",
    "    if raw_ci in valid_true:\n",
    "        IS_CI = True\n",
    "    elif raw_ci in valid_false:\n",
    "        IS_CI = False\n",
    "    else:\n",
    "        IS_CI = True  # Default safe\n",
    "\n",
    "    # Force Mock Mode if binaries are missing (Logic Update: Explicit Fallback)\n",
    "    if missing_binaries:\n",
    "        if not IS_CI:\n",
    "            print(\n",
    "                \"Missing binaries detected. Switching to Mock Mode.\"\n",
    "            )  # Visible in logs\n",
    "            fallback_msg = mo.md(\n",
    "                f\"\"\"\n",
    "                ::: warning\n",
    "                **Missing Binaries:** {\", \".join(missing_binaries)}\n",
    "\n",
    "                **FALLBACK TRIGGERED**: Switching to **Mock Mode** despite `CI={raw_ci}` because required simulation tools are not found in PATH.\n",
    "\n",
    "                **To Run in Real Mode:**\n",
    "                You must install the external physics codes:\n",
    "                1.  **Quantum Espresso (`pw.x`)**: [Installation Guide](https://www.quantum-espresso.org/Doc/user_guide/node10.html)\n",
    "                2.  **LAMMPS (`lmp`)**: [Installation Guide](https://docs.lammps.org/Install.html)\n",
    "                3.  **Pacemaker (`pace_train`)**: [Installation Guide](https://pacemaker.readthedocs.io/en/latest/)\n",
    "\n",
    "                After installation, ensure they are in your system `$PATH` and restart this notebook.\n",
    "                :::\n",
    "                \"\"\"\n",
    "            )\n",
    "        IS_CI = True\n",
    "\n",
    "    mode_name = \"Mock Mode (CI)\" if IS_CI else \"Real Mode (Production)\"\n",
    "\n",
    "    # Render Status Table\n",
    "    status_md = f\"\"\"\n",
    "    ### System Status: **{mode_name}**\n",
    "\n",
    "    | Binary | Status | Path |\n",
    "    | :--- | :--- | :--- |\n",
    "    \"\"\"\n",
    "    for binary in required_binaries:\n",
    "        if binary in found_binaries:\n",
    "            status_md += (\n",
    "                f\"| `{binary}` | ✅ Found | `{found_binaries[binary]}` |\\n\"\n",
    "            )\n",
    "        else:\n",
    "            status_md += f\"| `{binary}` | ❌ Missing | - |\\n\"\n",
    "\n",
    "    mo.md(status_md)\n",
    "else:\n",
    "    mo.md(\n",
    "        \"::: error\\n**Fatal Error**: Standard libraries `os` or `shutil` are not available.\\n:::\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emfo",
   "metadata": {
    "marimo": {
     "name": "constants_config"
    }
   },
   "outputs": [],
   "source": [
    "mo.md(\n",
    "    \"\"\"\n",
    "    ::: danger\n",
    "    **SECURITY WARNING: MOCK DATA GENERATION**\n",
    "\n",
    "    The following constant defines dummy content for Pseudopotential (`.UPF`) files.\n",
    "    This is **strictly for testing/CI environments** where real physics data is unavailable.\n",
    "\n",
    "    **Why Mock Data?** Real pseudopotentials are large binary files that may have licensing restrictions. In Mock Mode, we generate harmless placeholders to ensure the file I/O logic of the pipeline works correctly without needing actual physics data.\n",
    "\n",
    "    **NEVER** use these dummy files for actual scientific calculations as they will produce meaningless results.\n",
    "    :::\n",
    "    \"\"\"\n",
    ")\n",
    "# Constant definition for Mock Data Security\n",
    "# Minimal content to satisfy file existence checks without mimicking real physics data\n",
    "SAFE_DUMMY_UPF_CONTENT = \"# MOCK UPF FILE: FOR TESTING PURPOSES ONLY. DO NOT USE FOR PHYSICS.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hstk",
   "metadata": {
    "marimo": {
     "name": "setup_config"
    }
   },
   "outputs": [],
   "source": [
    "config = None\n",
    "config_dict = None\n",
    "pseudos = None\n",
    "strategy = \"random\"  # Default strategy\n",
    "tutorial_dir = None\n",
    "tutorial_tmp_dir = None\n",
    "setup_msg = None\n",
    "\n",
    "if (\n",
    "    PathRef is None\n",
    "    or atexit is None\n",
    "    or tempfile is None\n",
    "    or uuid is None\n",
    "    or os is None\n",
    "):\n",
    "    setup_msg = mo.md(\n",
    "        \"::: error\\n**Fatal Error**: Standard libraries `pathlib`, `atexit`, `tempfile`, `uuid`, or `os` are not available.\\n:::\"\n",
    "    )\n",
    "elif HAS_PYACEMAKER and PYACEMAKERConfig:\n",
    "    try:\n",
    "        # Check for write permissions in CWD\n",
    "        cwd = PathRef.cwd()\n",
    "        if not os.access(cwd, os.W_OK):\n",
    "            raise PermissionError(\n",
    "                f\"Current working directory '{cwd}' is not writable. Cannot create temporary workspace.\"\n",
    "            )\n",
    "\n",
    "        # Create temporary directory in CWD for security compliance (Pydantic validation requires path inside CWD)\n",
    "        # Use full hex for robustness\n",
    "        unique_suffix = uuid.uuid4().hex\n",
    "        tutorial_tmp_dir = tempfile.TemporaryDirectory(\n",
    "            prefix=f\"pyacemaker_tutorial_{unique_suffix}_\", dir=cwd\n",
    "        )\n",
    "        tutorial_dir = PathRef(tutorial_tmp_dir.name)\n",
    "\n",
    "        # Register cleanup on exit to ensure directory is removed even on crash\n",
    "        def _cleanup_handler():\n",
    "            try:\n",
    "                if tutorial_tmp_dir:\n",
    "                    tutorial_tmp_dir.cleanup()\n",
    "                    print(f\"Cleanup: Removed {tutorial_dir}\")\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        atexit.register(_cleanup_handler)\n",
    "\n",
    "        setup_msg = mo.md(f\"Initializing Tutorial Workspace at: `{tutorial_dir}`\")\n",
    "\n",
    "        pseudos = {\n",
    "            \"Fe\": \"Fe.pbe.UPF\",\n",
    "            \"Pt\": \"Pt.pbe.UPF\",\n",
    "            \"Mg\": \"Mg.pbe.UPF\",\n",
    "            \"O\": \"O.pbe.UPF\",\n",
    "        }\n",
    "\n",
    "        if IS_CI:\n",
    "            print(\"creating dummy upf files\")\n",
    "            # Security: Ensure content is static and harmless\n",
    "            for element, filename in pseudos.items():\n",
    "                pseudo_path = tutorial_dir / filename\n",
    "                if not pseudo_path.exists():\n",
    "                    with open(pseudo_path, \"w\") as f:\n",
    "                        f.write(SAFE_DUMMY_UPF_CONTENT)\n",
    "\n",
    "        # Determine strategy based on API key availability\n",
    "        # Logic: If no API key, force \"random\" to avoid M3GNet errors.\n",
    "        if has_api_key and not IS_CI:\n",
    "            # In Real Mode with API Key, we could use adaptive\n",
    "            # For consistency in tutorial, we stick to random but log it\n",
    "            print(\n",
    "                \"API Key present. 'adaptive' strategy is available, but using 'random' for tutorial consistency.\"\n",
    "            )\n",
    "\n",
    "        # Define configuration\n",
    "        config_dict = {\n",
    "            \"version\": \"0.1.0\",\n",
    "            \"project\": {\"name\": \"FePt_MgO\", \"root_dir\": str(tutorial_dir)},\n",
    "            \"logging\": {\"level\": \"INFO\"},\n",
    "            \"orchestrator\": {\"max_cycles\": 2 if IS_CI else 10},\n",
    "            \"oracle\": {\n",
    "                \"dft\": {\n",
    "                    \"pseudopotentials\": {\n",
    "                        k: str(tutorial_dir / v) if IS_CI else v\n",
    "                        for k, v in pseudos.items()\n",
    "                    }\n",
    "                },\n",
    "                \"mock\": IS_CI,\n",
    "            },\n",
    "            \"trainer\": {\n",
    "                \"potential_type\": \"pace\",\n",
    "                \"mock\": IS_CI,\n",
    "                \"max_epochs\": 1,\n",
    "            },\n",
    "            \"dynamics_engine\": {\n",
    "                \"engine\": \"lammps\",\n",
    "                \"mock\": IS_CI,\n",
    "                \"gamma_threshold\": 0.5,\n",
    "                \"timestep\": 0.001,\n",
    "                \"n_steps\": 100,\n",
    "            },\n",
    "            \"structure_generator\": {\"strategy\": strategy},  # Dynamic strategy\n",
    "            \"validator\": {\"test_set_ratio\": 0.1},\n",
    "        }\n",
    "        config = PYACEMAKERConfig(**config_dict)\n",
    "        (tutorial_dir / \"data\").mkdir(exist_ok=True, parents=True)\n",
    "    except Exception as e:\n",
    "        setup_msg = mo.md(\n",
    "            f\"::: error\\n**Setup Failed:** Could not create temporary directory or config. {e}\\n:::\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nWHF",
   "metadata": {
    "marimo": {
     "name": "section2_md"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iLit",
   "metadata": {
    "marimo": {
     "name": "custom_generator_md"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZHCJ",
   "metadata": {
    "marimo": {
     "name": "define_generator"
    }
   },
   "outputs": [],
   "source": [
    "TutorialStructureGenerator = None\n",
    "\n",
    "if StructureGenerator is not None:\n",
    "\n",
    "    class TutorialStructureGenerator(StructureGenerator):\n",
    "        \"\"\"Custom generator for Fe/Pt on MgO tutorial.\n",
    "\n",
    "        Ensures realistic structures are used even in Mock Mode.\n",
    "        \"\"\"\n",
    "\n",
    "        def run(self) -> ModuleResult:\n",
    "            return ModuleResult(status=\"success\", metrics=Metrics())\n",
    "\n",
    "        def generate_initial_structures(self):\n",
    "            \"\"\"Generate initial structures (MgO, Fe, Pt, MgO surface).\"\"\"\n",
    "            # Use ase.build inside method to avoid global scope issues if not imported\n",
    "            from ase.build import bulk, surface\n",
    "\n",
    "            # 1. MgO Bulk\n",
    "            atoms = bulk(\"MgO\", \"rocksalt\", a=4.21)\n",
    "            yield self._wrap(atoms, \"initial_MgO_bulk\")\n",
    "\n",
    "            # 2. Fe Bulk\n",
    "            atoms = bulk(\"Fe\", \"bcc\", a=2.87)\n",
    "            yield self._wrap(atoms, \"initial_Fe_bulk\")\n",
    "\n",
    "            # 3. Pt Bulk\n",
    "            atoms = bulk(\"Pt\", \"fcc\", a=3.92)\n",
    "            yield self._wrap(atoms, \"initial_Pt_bulk\")\n",
    "\n",
    "            # 4. MgO Surface\n",
    "            atoms = surface(bulk(\"MgO\", \"rocksalt\", a=4.21), (0, 0, 1), 2)\n",
    "            atoms.center(vacuum=10.0, axis=2)\n",
    "            yield self._wrap(atoms, \"initial_MgO_surf\")\n",
    "\n",
    "        def _wrap(self, atoms, tag):\n",
    "            return StructureMetadata(\n",
    "                features={\"atoms\": atoms},\n",
    "                tags=[tag, \"tutorial\"],\n",
    "                status=StructureStatus.NEW,\n",
    "            )\n",
    "\n",
    "        def generate_local_candidates(self, seed, n_candidates, cycle=1):\n",
    "            \"\"\"Generate perturbed candidates.\"\"\"\n",
    "            if not seed or \"atoms\" not in seed.features:\n",
    "                return\n",
    "\n",
    "            atoms_ref = seed.features[\"atoms\"]\n",
    "            for i in range(n_candidates):\n",
    "                atoms = atoms_ref.copy()\n",
    "                atoms.rattle(stdev=0.1)\n",
    "                yield self._wrap(atoms, f\"candidate_c{cycle}_{i}\")\n",
    "\n",
    "        def generate_batch_candidates(self, seeds, n_candidates_per_seed, cycle=1):\n",
    "            for s in seeds:\n",
    "                yield from self.generate_local_candidates(\n",
    "                    s, n_candidates_per_seed, cycle\n",
    "                )\n",
    "\n",
    "        def get_strategy_info(self):\n",
    "            return {\"strategy\": \"tutorial_custom\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ROlb",
   "metadata": {
    "marimo": {
     "name": "run_simulation"
    }
   },
   "outputs": [],
   "source": [
    "orchestrator = None\n",
    "results = []  # Define at start to ensure it exists in cell scope\n",
    "metrics_dict = None\n",
    "module_result = None\n",
    "sim_output = None\n",
    "\n",
    "# Robust checks\n",
    "if not HAS_PYACEMAKER:\n",
    "    sim_output = mo.md(\n",
    "        \"::: warning\\nSkipping simulation: `pyacemaker` not available.\\n:::\"\n",
    "    )\n",
    "elif Orchestrator is None:\n",
    "    sim_output = mo.md(\n",
    "        \"::: error\\n**Fatal Error**: `Orchestrator` class not found.\\n:::\"\n",
    "    )\n",
    "elif config is None:\n",
    "    sim_output = mo.md(\n",
    "        \"::: error\\n**Fatal Error**: Configuration `config` is None.\\n:::\"\n",
    "    )\n",
    "else:\n",
    "    # Step 1: Initialization\n",
    "    try:\n",
    "        # Use custom generator if available to ensure realistic structures\n",
    "        gen_instance = None\n",
    "        if TutorialStructureGenerator:\n",
    "            gen_instance = TutorialStructureGenerator(config)\n",
    "            print(\"Using Custom Tutorial Structure Generator (Fe/Pt/MgO).\")\n",
    "\n",
    "        orchestrator = Orchestrator(config, structure_generator=gen_instance)\n",
    "        print(\"Orchestrator Initialized successfully.\")\n",
    "    except Exception as e:\n",
    "        sim_output = mo.md(\n",
    "            f\"\"\"\n",
    "            ::: error\n",
    "            **Initialization Error:**\n",
    "            Failed to initialize the Orchestrator. Please check your configuration.\n",
    "\n",
    "            Details: `{e}`\n",
    "            :::\n",
    "            \"\"\"\n",
    "        )\n",
    "        # Orchestrator remains None\n",
    "\n",
    "    # Step 2: Execution (only if initialized)\n",
    "    if orchestrator is not None:\n",
    "        try:\n",
    "            print(\"Starting Active Learning Pipeline...\")\n",
    "\n",
    "            # Use the high-level run() method to execute the full pipeline\n",
    "            module_result = orchestrator.run()\n",
    "\n",
    "            print(f\"Pipeline finished with status: {module_result.status}\")\n",
    "\n",
    "            # Extract cycle history from metrics for visualization\n",
    "            if module_result and module_result.metrics:\n",
    "                metrics_dict = module_result.metrics.model_dump()\n",
    "                results = metrics_dict.get(\"history\", [])\n",
    "            else:\n",
    "                print(\"Warning: No metrics returned from pipeline.\")\n",
    "\n",
    "            if not results:\n",
    "                print(\"Warning: No cycle history found in results.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            sim_output = mo.md(\n",
    "                f\"\"\"\n",
    "                ::: error\n",
    "                **Runtime Error:**\n",
    "                The Active Learning Pipeline failed during execution.\n",
    "\n",
    "                Details: `{e}`\n",
    "                :::\n",
    "                \"\"\"\n",
    "            )\n",
    "            print(f\"Critical Runtime Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qnkX",
   "metadata": {
    "marimo": {
     "name": "visualize"
    }
   },
   "outputs": [],
   "source": [
    "data = None\n",
    "rmse_values = None\n",
    "v = None\n",
    "fig_training = None\n",
    "\n",
    "if HAS_PYACEMAKER and results and plt:\n",
    "    rmse_values = []\n",
    "    for metrics in results:\n",
    "        v = 0.0\n",
    "        # Defensive programming: Handle various potential formats of metrics\n",
    "        if hasattr(metrics, \"rmse_energy\"):\n",
    "            v = getattr(metrics, \"rmse_energy\", 0.0)\n",
    "        elif hasattr(metrics, \"energy_rmse\"):\n",
    "            v = getattr(metrics, \"energy_rmse\", 0.0)\n",
    "\n",
    "        # If still 0.0 or not found, try Pydantic dump\n",
    "        if v == 0.0 and hasattr(metrics, \"model_dump\"):\n",
    "            try:\n",
    "                data = metrics.model_dump()\n",
    "                v = data.get(\"rmse_energy\", data.get(\"energy_rmse\", 0.0))\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        rmse_values.append(v)\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(range(1, len(results) + 1), rmse_values, \"b-o\")\n",
    "    plt.title(\"Training Convergence\")\n",
    "    plt.xlabel(\"Cycle\")\n",
    "    plt.ylabel(\"RMSE (eV/atom)\")\n",
    "    plt.grid(True)\n",
    "    # In Marimo, plt.gca() or plt.gcf() is captured automatically.\n",
    "    # Explicitly returning the figure is good practice.\n",
    "    fig_training = plt.gcf()\n",
    "    plt.show() # Ensure display in standard output contexts if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TqIu",
   "metadata": {
    "marimo": {
     "name": "section3_md"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Vxnm",
   "metadata": {
    "marimo": {
     "name": "explain_potential_helper"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ulZA",
   "metadata": {
    "marimo": {
     "name": "section4_md"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfG",
   "metadata": {
    "marimo": {
     "name": "run_analysis"
    }
   },
   "outputs": [],
   "source": [
    "# We print the markdown here because we return variables.\n",
    "# In Marimo interactive mode, this markdown might not be prominently displayed\n",
    "# if not returned, but we need to return variables.\n",
    "# Using print as fallback for logs.\n",
    "print(\"Running Analysis: L10 Ordering Phase Transition (Mock)\")\n",
    "\n",
    "order_param = None\n",
    "time_steps = None\n",
    "fig_analysis = None\n",
    "analysis_output = None\n",
    "\n",
    "if HAS_PYACEMAKER and np and plt:\n",
    "    # Mock data for visualization\n",
    "    time_steps = np.linspace(0, 1e6, 50)\n",
    "    # Sigmoid function to simulate ordering transition\n",
    "    # Ensure exponent is within reasonable bounds to avoid overflow\n",
    "    exponent = -1e-5 * (time_steps - 3e5)\n",
    "    # Clip exponent to avoid overflow in exp (e.g., -700 to 700 usually safe for float64)\n",
    "    exponent = np.clip(exponent, -100, 100)\n",
    "    order_param = 1.0 / (1.0 + np.exp(exponent))\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(time_steps, order_param, \"r-\", linewidth=2, label=\"Order Parameter\")\n",
    "    plt.title(\"L10 Ordering Phase Transition (Mock)\")\n",
    "    plt.xlabel(\"Time (us)\")\n",
    "    plt.ylabel(\"Order Parameter (0=Disordered, 1=L10)\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    fig_analysis = plt.gcf()\n",
    "    plt.show()\n",
    "elif not HAS_PYACEMAKER:\n",
    "    analysis_output = mo.md(\n",
    "        \"::: warning\\nSkipping Analysis: `pyacemaker` not available.\\n:::\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Pvdt",
   "metadata": {
    "marimo": {
     "name": "cleanup"
    }
   },
   "outputs": [],
   "source": [
    "if tutorial_tmp_dir:\n",
    "    try:\n",
    "        tutorial_tmp_dir.cleanup()\n",
    "        print(\"Cleanup: Done.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Cleanup warning: {e}\")\n",
    "else:\n",
    "    print(\"Cleanup: No temporary directory to remove.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "marimo": {
   "marimo_version": "0.19.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
